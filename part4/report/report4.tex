\documentclass[12pt]{article}
\usepackage[a4paper,margin=2cm]{geometry}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{listings}
\usepackage{amsmath}
\usepackage{Tabbing}
\usepackage{biblatex}
\usepackage[affil-it]{authblk}
\usepackage{lmodern}
\usepackage{titlesec}
\usepackage[skip=2pt,font=footnotesize]{caption}
\usepackage{ulem}
%\usepackage{titlesec}



%\titlespacing{\paragraph}{1.5em}{0.5em}{0.5em}
\titlespacing{\paragraph}{\parindent}{0.5em}{0.5em}

\addbibresource{refs.bib}
\renewcommand{\baselinestretch}{1.05}
%\renewcommand{\familydefault}{\sfdefault}

\lstset{basicstyle=\ttfamily\fontseries{lc}\selectfont,breaklines=true,tabsize=4}

\begin{document}

\title{Building a compiler\\\Large for an yet unnamed language\\\small Polymorphism in a C-like programming language}

\author{Diogo César Ferreira\\11/0027931}
\affil{University of Brasília}
\maketitle

\section{Introduction}
Programming languages are languages that can be converted into sets of instructions to be
executed by a computer. This conversion process is called translation (or compilation) and
is done by software known as compilers. As programming languages evolved, we observe an
increasing variety of abstractions to accommodate for new programming paradigms and
techniques, which also bring them closer to the domain of the problems they are set
out to solve and away from the specificities of architecture set implementations \cite{Aho2007}.

One such abstraction is polymorphism. In typed languages, symbols (named identifiers
for entities such as variables or functions) are constrained by their data type.
If polymorphism is available, we are able to interact with different data types
through a single interface, for instance, by allowing multiple types to be assigned
to a given symbol. Polymorphism improves code readability and helps keeping the namespace
clean by allowing functions to be identified by their expected behavior rather than
contrived by the types of their arguments. Polymorphism is also one of the key features
in object-oriented programming \cite{Aho2007, Strachey2000}.

Aside from the possibility to perform arithmetical operations over a few different
data types (integers, floating point and pointers), the C programming language does
not support polymorphism. In this work we seek to provide polymorphism in the form
of function overloading - where polymorphic functions may have multiple definitions
according to their argument types - to a simplified subset of the C programming language.
The grammar of the language is presented in the following subsection.


\subsection{Language features}
The following table summarizes what word patterns are part of the language we are designing.
These patterns should be recognized by the scanner, and therefore are provided as an input file
for the FLEX \cite{FLEX} scanner generator (see attached file ``language.l''):

%\paragraph{}
\begin{tabular}{lccccccccc}
\textbf{Data types}                      & void & char & int & float &         &      &      &   &   \\
\textbf{Keywords}                        & if   & else & do  & while & return  &      &      &   &   \\
\textbf{Arithmetical operators}          & $+$  & $-$  & $*$ & $/$   & $\%$    & $++$ & $--$ &   &   \\
\textbf{Comparison operators}            & <    & >    & <=  & >=    & ==      & !=   &      &   &   \\
\textbf{Logical operators}               & \&\& & ||   & !   &       &         &      &      &   &   \\
\textbf{Assignment operator}             & =    &      &     &       &         &      &      &   &   \\
\textbf{Character/string delimiters}     & '    & "    &     &       &         &      &      &   &   \\
\textbf{Array indexers}                  & [    & ]    &     &       &         &      &      &   &   \\
\textbf{Scope delims./init lists}        & \{   & \}   &     &       &         &      &      &   &   \\
\textbf{End of statement mark}           & ;    &      &     &       &         &      &      &   &   \\
\textbf{Function args/calls}             & (    & )    &     &       &         &      &      &   &   \\
\textbf{List element separator}          & ,    &      &     &       &         &      &      &   &   \\
\textbf{Comment delimiters}              & /*   & */   & //  &       &         &      &      &   &   \\
\end{tabular}

\vspace*{1cm}

\begin{tabular}{ll}
\textbf{Character constants}            & text delimited by single quotation marks (') \\
\textbf{String literals}                & text delimited by double quotation marks (") \\
\textbf{Integer decimal constants}      & e.g. 1, 2, 100, -5, +7                       \\
\textbf{Integer hexadecimal constants}  & e.g. 0x01, -0xA, +0x123                      \\
\textbf{Floating-point constants}       & g.g. 0.0, -1.234, +3.14                      \\
\textbf{Comments and white space}       & are ignored.                                 \\
\end{tabular}

\subsection{Formal description}

Our languate's grammar contains elements taken from the one presented by \textcite{Harbison2002},
which is a compilation from the many versions of the C grammar specified by the ISO C Standard
along the years. Our grammar follows the general structure of the C language's grammar.
We aim to provide a simplified version of the C language with support for polymophic function
definitions, that is, which allows the programmer to define multiple function with the same name
but different argument types. The following grammar is also provided as an input file for the
GNU Bison \cite{BISON} parser generator (see attached file ``language.y''). Strikenthrough
rules are the ones that have been removed or changed from the previous version of our grammar.

\small
\begin{enumerate}
\item \begin{tabbing} start \= $\rightarrow$ \= declaration-list \\
\end{tabbing}

\item \begin{tabbing} declaration-list \= $\rightarrow$ \= declaration \\
	\> \hspace*{0.05cm} | \> declaration-list declaration \\
\end{tabbing}

\item \begin{tabbing} declaration \= $\rightarrow$ \= \sout{function-declarator \textbf{;}} \\
	\> \hspace*{0.05cm} | \> \sout{function-declarator compound-statement} \\
	\> \hspace*{0.05cm} | \> function-definiton \\
	\> \hspace*{0.05cm} | \> init-declarator \textbf{;} \\
\end{tabbing}

\item \begin{tabbing} init-declarator \= $\rightarrow$ \= \sout{declarator} \\
	\> \hspace*{0.05cm} | \> \sout{declarator \textbf{=} initializer} \\
	\> \hspace*{0.05cm} | \> type \textbf{IDENTIFIER}                                                                                                 \\
	\> \hspace*{0.05cm} | \> type \textbf{IDENTIFIER} \textbf{=} assignment-expression                                                              \\
	\> \hspace*{0.05cm} | \> type \textbf{IDENTIFIER} \textbf{[} assignment-expression \textbf{]}                                                 \\
	\> \hspace*{0.05cm} | \> type \textbf{IDENTIFIER} \textbf{[} \textbf{]} \textbf{=} \textbf{\{} initializer-list \textbf{\}}               \\
	\> \hspace*{0.05cm} | \> type \textbf{IDENTIFIER} \textbf{[} \textbf{]} \textbf{=} \textbf{\{} initializer-list \textbf{,} \textbf{\}}  \\
	\> \hspace*{0.05cm} | \> type \textbf{IDENTIFIER} \textbf{[} \textbf{]} \textbf{=} \textbf{STRING-LITERAL}                                  \\
\end{tabbing}


\item \begin{tabbing} \sout{declarator} \= $\rightarrow$ \= \sout{type \textbf{IDENTIFIER}} \\
	\> \hspace*{0.05cm} | \> \sout{type \textbf{IDENTIFIER} \textbf{[} \textbf{]}} \\
	\> \hspace*{0.05cm} | \> \sout{type \textbf{IDENTIFIER} \textbf{[} assignment-expression \textbf{]}}\\
\end{tabbing}

\item \begin{tabbing} \sout{initializer} \= $\rightarrow$ \= \sout{assignment-expression} \\
	\> \hspace*{0.05cm} | \> \sout{\textbf{\{} initializer-list \textbf{\}}} \\
	\> \hspace*{0.05cm} | \> \sout{\textbf{\{} initializer-list \textbf{,} \textbf{\}}} \\
\end{tabbing}

\item \begin{tabbing} initializer-list \= $\rightarrow$ \= \sout{initializer} \\
	\> \hspace*{0.05cm} | \> \sout{initializer-list \textbf{,} initializer} \\
	\> \hspace*{0.05cm} | \> assignment-expression \\
	\> \hspace*{0.05cm} | \> initializer-list \textbf{,} assignment-expression \\
\end{tabbing}

\item \begin{tabbing} \sout{function-declarator} \= $\rightarrow$ \= \sout{type \textbf{IDENTIFIER} \textbf{(} parameter-list \textbf{)}} \\
	\> \hspace*{0.05cm} | \> \sout{type \textbf{IDENTIFIER} \textbf{(} \textbf{)} } \\
	\> \hspace*{0.05cm} | \> \sout{type \textbf{IDENTIFIER} \textbf{(} \textbf{VOID} \textbf{)}} \\
\end{tabbing}

\item \begin{tabbing} function-definition \= $\rightarrow$ \= type \textbf{IDENTIFIER} \textbf{(} argument-list \textbf{)} \textbf{\{} statement-list \textbf{\}}   \\
	\> \hspace*{0.05cm} 	|\>  type \textbf{IDENTIFIER} \textbf{(} \textbf{VOID} \textbf{)}          \textbf{\{} statement-list \textbf{\}}   \\
	\> \hspace*{0.05cm} 	|\>  type \textbf{IDENTIFIER} \textbf{(} \textbf{)}               \textbf{\{} statement-list \textbf{\}}   \\
	\> \hspace*{0.05cm} 	|\>  type \textbf{IDENTIFIER} \textbf{(} argument-list \textbf{)} \textbf{\{}                \textbf{\}}   \\
	\> \hspace*{0.05cm} 	|\>  type \textbf{IDENTIFIER} \textbf{(} \textbf{VOID} \textbf{)}          \textbf{\{}                \textbf{\}}   \\
	\> \hspace*{0.05cm} 	|\>  type \textbf{IDENTIFIER} \textbf{(} \textbf{)}               \textbf{\{}                \textbf{\}}   \\
\end{tabbing}

\item \begin{tabbing} \sout{parameter-list} \= $\rightarrow$ \= \sout{declarator} \\
	\> \hspace*{0.05cm} | \> \sout{parameter-list \textbf{,} declarator} \\
\end{tabbing}

\item \begin{tabbing} argument-list \= $\rightarrow$ \= argument \\
	\> \hspace*{0.05cm} | \> argument-list \textbf{,} argument
\end{tabbing}

\item \begin{tabbing} argument \= $\rightarrow$ \= type \textbf{IDENTIFIER} \\
	\> \hspace*{0.05cm} | \> type \textbf{IDENTIFIER} \textbf{[} \textbf{]} \\
\end{tabbing}

\item \begin{tabbing} compound-statement \= $\rightarrow$ \= \textbf{\{} \textbf{\}} \\
	\> \hspace*{0.05cm} | \> \textbf{\{} statement-list \textbf{\}} \\
\end{tabbing}

\item \begin{tabbing} statement-list \= $\rightarrow$ \= statement \\
	\> \hspace*{0.05cm} | \> statement-list statement
\end{tabbing}

\item \begin{tabbing} statement \= $\rightarrow$ \= \textbf{;} \\
	\> \hspace*{0.05cm} | \> init-declarator \textbf{;} \\
	\> \hspace*{0.05cm} | \> assignment-expression \textbf{;} \\
	\> \hspace*{0.05cm} | \> conditional-statement \\
	\> \hspace*{0.05cm} | \> iteration-statement \\
	\> \hspace*{0.05cm} | \> compound-statement \\
	\> \hspace*{0.05cm} | \> return-statement \textbf{;} \\
\end{tabbing}

\item \begin{tabbing} conditional-statement \= $\rightarrow$ \= \textbf{IF} \textbf{(} assignment-expression \textbf{)} compound-statement \\
	\> \hspace*{0.05cm} | \> \textbf{IF} \textbf{(} assignment-expression \textbf{)} compound-statement \textbf{ELSE} compound-statement \\
\end{tabbing}

\item \begin{tabbing} iteration-statement \= $\rightarrow$ \= \textbf{WHILE} \textbf{(} assignment-expression \textbf{)} compound-statement \\
	\> \hspace*{0.05cm} | \> \textbf{DO} compound-statement \textbf{WHILE} \textbf{(} assignment-expression \textbf{)} \textbf{;} \\
\end{tabbing}

\item \begin{tabbing} return-statement \= $\rightarrow$ \= \textbf{RETURN} \\
	\> \hspace*{0.05cm} | \> \textbf{RETURN} assignment-expression \\
\end{tabbing}

\item \begin{tabbing} assignment-expression \= $\rightarrow$ \= logical-or-expression \\
	\> \hspace*{0.05cm} | \> postfix-expression \textbf{=} logical-or-expression \\
\end{tabbing}

\item \begin{tabbing} logical-or-expression \= $\rightarrow$ \= logical-and-expression \\
	\> \hspace*{0.05cm} | \> logical-or-expression \textbf{||} logical-and-expression \\
\end{tabbing}

\item \begin{tabbing} logical-and-expression \= $\rightarrow$ \= equality-expression \\
	\> \hspace*{0.05cm} | \> logical-and-expression \textbf{\&\&} equality-expression \\
\end{tabbing}

\item \begin{tabbing} equality-expression \= $\rightarrow$ \= relational-expression \\
	\> \hspace*{0.05cm} | \> equality-expression \textbf{==} relational-expression \\
	\> \hspace*{0.05cm} | \> equality-expression \textbf{!=} relational-expression \\
\end{tabbing}

\item \begin{tabbing} relational-expression \= $\rightarrow$ \= additive-expression \\
	\> \hspace*{0.05cm} | \> relational-expression \textbf{<}   additive-expression \\
	\> \hspace*{0.05cm} | \> relational-expression \textbf{>}   additive-expression \\
	\> \hspace*{0.05cm} | \> relational-expression \textbf{<=} additive-expression \\
	\> \hspace*{0.05cm} | \> relational-expression \textbf{>=} additive-expression \\
\end{tabbing}

\item \begin{tabbing} additive-expression \= $\rightarrow$ \= multiplicative-expression \\
	\> \hspace*{0.05cm} | \> additive-expression \textbf{+} multiplicative-expression \\
	\> \hspace*{0.05cm} | \> additive-expression \textbf{--} multiplicative-expression \\
\end{tabbing}

\item \begin{tabbing} multiplicative-expression \= $\rightarrow$ \= \sout{postfix-expression} unary-expression \\
	\> \hspace*{0.05cm} | \> multiplicative-expression \textbf{*}   \sout{postfix-expression} unary-expression \\
	\> \hspace*{0.05cm} | \> multiplicative-expression \textbf{/}   \sout{postfix-expression} unary-expression \\
	\> \hspace*{0.05cm} | \> multiplicative-expression \textbf{\%}  \sout{postfix-expression} unary-expression \\
\end{tabbing}

\item \begin{tabbing} unary-expression \= $\rightarrow$ \= postfix-expression \\
	\> \hspace*{0.05cm} | \>  \textbf{!}   unary-expression \\
	\> \hspace*{0.05cm} | \>  \textbf{--}   unary-expression \\
	\> \hspace*{0.05cm} | \>  \textbf{-- --}  unary-expression \\
	\> \hspace*{0.05cm} | \>  \textbf{++}  unary-expression \\
\end{tabbing}

\item \begin{tabbing} postfix-expression \= $\rightarrow$ \= primary-expression \\
	\> \hspace*{0.05cm} | \> \sout{postfix-expression} \textbf{IDENTIFIER} \textbf{[} assignment-expression \textbf{]} \\
	\> \hspace*{0.05cm} | \> \sout{postfix-expression} \textbf{IDENTIFIER} \textbf{(} \textbf{)} \\
	\> \hspace*{0.05cm} | \> \sout{postfix-expression} \textbf{IDENTIFIER} \textbf{(} argument-call-list \textbf{)} \\
	\> \hspace*{0.05cm} | \> \sout{postfix-expression \textbf{++}} \\
	\> \hspace*{0.05cm} | \> \sout{postfix-expression \textbf{-- --}} \\
\end{tabbing}

\item \begin{tabbing} primary-expression \= $\rightarrow$ \= \textbf{IDENTIFIER} \\
	\> \hspace*{0.05cm} | \> \textbf{CONSTANT-INT} \\
	\> \hspace*{0.05cm} | \> \textbf{CONSTANT-HEX} \\
	\> \hspace*{0.05cm} | \> \textbf{CONSTANT-FLOAT} \\
	\> \hspace*{0.05cm} | \> \textbf{CONSTANT-CHAR} \\
	\> \hspace*{0.05cm} | \> \textbf{STRING-LITERAL} \\
	\> \hspace*{0.05cm} | \> \textbf{(} assignment-expression \textbf{)} \\
\end{tabbing}

\item \begin{tabbing} argument-call-list \= $\rightarrow$ \= assignment-expression \\
	\> \hspace*{0.05cm} | \> argument-call-list \textbf{,} assignment-expression
\end{tabbing}

\item \begin{tabbing} type \= $\rightarrow$ \= \textbf{VOID} \\
	\> \hspace*{0.05cm} | \> \textbf{INT} \\
	\> \hspace*{0.05cm} | \> \textbf{FLOAT} \\
	\> \hspace*{0.05cm} | \> \textbf{CHAR}
\end{tabbing}

\end{enumerate}
\normalsize

\subsection{Grammar changes}
\paragraph{Rule 3:} the removed productions were replaced by the \textit{function-definition} variable.
Function declaration without definition has beem removed in this version due to implementation issues,
but might be added once again in a future version.

\paragraph{Rules 4, 5 and 6:} the \textit{declarator} and \textit{initializer} variables have been
removed, but their productions (rules 5 and 6) are now parte of rule 4. This was done because
of changes in the underlying data structures used to hold token data.

\paragraph{Rules 8 and 9:} \textit{function-declarator} (rule 8) was removed and replaced by
\textit{function-definition} (rule 9). The previous version used the variable
\textit{compound-statement} for the function body, but this resulted in difficulties
to implement scope resolution.

\paragraph{Rules 10, 11 and 12:} the variable \textit{parameter-list} (rule 10) has been
refactored into \textit{argument-list} (rule 11) and \textit{argument} (rule 12). This part of
the grammar is now handled by a specific data structure used to hold a function's argument list.

\paragraph{Rules 25 and 26:} unary operators were introduced, mainly to allow the negation
of a value.

\paragraph{Rule 27:} postfix increment and decrement operators were moved to rule 26 as unary prefix
operators. The other productions in this rule were changed to allow only identifiers on their left-hand
side, since these productions represent either array indexing or function calls, and are now handled
by specific functions and no longer require the \textit{postfix-expression} variable to be resolved
beforehand (an expression instead of an identifier here would be invalid anyway).

\subsection{Input / output}
Input and output operations are not specified in our language's grammar. However, these will be provided
in the form of special polymorphic functions available to the user, akin to a small built-in
\texttt{stdio.h} library. The available functions will have the following signatures:

\begin{lstlisting}[language=C]
void write(int i);    //
void write(char c);   // output values to the standard output
void write(char[] s); //
void write(float f);  //

void read(int i);    //
void read(char c);   // receives values from the standard input
void read(char[] s); //
void read(float f);  //
\end{lstlisting}

\subsection{Semantics}
We present some use cases in which polymorphic functions would be useful. Functions with the same behavior, but different argument types:

\begin{lstlisting}[language=C]
int   i = -1;
float f = -1.0;
abs(i); // return the absolute value of i
abs(f); // return the absolute value of f
        // In C, abs does not accept a floating-point argument
        // we must use fabs instead
\end{lstlisting}

In this simple example, the abs function could compute the absolute of any numeric value passed as argument. The type constrains in C, however, do not allow the abs function to be called with a floating-point argument.

Functions with different behavior, but the same "intuitive meaning" for the programmer

\begin{lstlisting}[language=C]
int  i[3] = { 9, 2, 5 };
char w[][9] = { "word", "vocable", "locution" };

sort(i); // The user implements a sorting function for integer vectors
sort(w); // The user implements a lexicographic or alphabetic
         // sorting function for string vectors
\end{lstlisting}

The implementation of a sorting function for integers and strings would be considerably distinct. However, intuitively a programmer might expect some notion of ordering to be present in arrays of strings. This can also be applied to functions with different number of arguments:

\begin{lstlisting}[language=C]
// Should return the lowest of either x or y
int min(int x, int y) {
	if (x <= y) { return x; }
	else { return y; }
}

// Should also return the lowest of either x, y or z
int min(int x, int y, int z) {
	if (x <= y) {
		if (x <= z) { return x; }
		else { return z; }
	} else {
		if (y <= z) { return y; }
		else { return z; }
	}
}
\end{lstlisting}




\clearpage

\section{The compiler}
In this section we will describe the compiler's implementation for our yet unnamed programming
language, which has the responsibility to read the input text and ultimately convert it into an
executable file. The first step is to define the patterns which are to be recognized by the scanner.
Then, the Fast Lexical Analyzer (FLEX) \cite{FLEX} software is used to generate the lexical
analyzer's main functionality. Moreover we provide the language's grammar to the GNU Bison parser
generator \cite{BISON} which generates the syntax analyzer. Additional routines for input, output,
error handling and data structures to build the syntax tree and symbol table were also implemented
and will be explained in detail later.


\subsection{Program usage}
The program takes one argument which should be a path to the input file.

\begin{lstlisting}
$ ./a.out <input_file>
\end{lstlisting}

The program will then output the symbol table along with the
annotated syntax tree generated from the input file, if it is part of the language.
Should there be errors, the program will instead list them along with their
positions in the text (line and column numbers, where tabs count as 4 columns).

\subsection{Compilation instructions}

\begin{enumerate}
\item (Optional) Generate the lexical analyzer .c source code through FLEX
\begin{lstlisting}
$ flex language.l
\end{lstlisting}

\item (Optional) Generate the syntax analyzer .c source code through GNU Bison
\begin{lstlisting}
$ bison -Wall language.y
\end{lstlisting}

\item Compile the program
\begin{lstlisting}
$ gcc -std=c18 -m64 -O3 src/main.c src/node.c src/node-list.c src/table.c src/table-stack.c src/arg-list.c src/parser.c src/scanner.c
\end{lstlisting}

\item Alternatively, a makefile has also been provided which will run all commands
\begin{lstlisting}
$ make
OR
$ make flex   # for step 1
$ make bison  # for step 2
$ make rel    # for step 3
\end{lstlisting}
\end{enumerate}

\paragraph{Technical specifications}
\paragraph{Operating system:} Debian GNU/Linux bullseye/sid (testing release)
\paragraph{Compiler version:} gcc (Debian 9.2.1-17) 9.2.1 20191102
\paragraph{FLEX version:} flex 2.6.4
\paragraph{GNU Bison version:} bison (GNU Bison) 3.4.2

\subsection{Attached files}
\begin{lstlisting}
a.out       - Precompiled x64 binary
language.l  - FLEX definitions file
language.y  - BISON definitions file
makefile    - 
src/        - Source code folder
tests/      - Test input files
\end{lstlisting}


\subsection{Error handling}
As the program reads the input file, the parser requests tokens from the scanner, who splits the
input text into tokens and relays them back to the parser. If an error is found, a message is
sent to \texttt{stderr} indicating the position (line and column) in the text where it was found,
and whether it was detected by the scanner, the parser or the semantic analyzer.


\subsubsection{Lexical errors}
If the scanner finds an error, it outputs a message and returns a special error token to the parser.
Following suggestions, identifiers with more than 32 characters are no longer considered an error
and only output a warning if they are found, which does not block compilation.
The scanner recognizes the following errors (Table \ref{tab:scanner-errors}).

\begin{table}[h]
\centering
\captionsetup{width=0.7\textwidth}
\caption{Lexical errors and their associated tokens. The tokens are returned
to the parser and the program continues analyzing the rest of the text.}
\label{tab:scanner-errors}
\begin{tabular} {c c}
\hline
Error type & Token type \\
\hline
Unrecognized token & \texttt{UNRECOGNIZED\_TOKEN} \\
Malformed character constant & \texttt{INVALID\_CHAR\_CONST} \\
\hline
\end{tabular}
\end{table}

\subsubsection{Syntax errors}
Syntax errors are thrown from the parser when it is unable to complete a shift or reduce
operation. To allow the parser to continue reading the input, the built in \texttt{error}
token is included in some of the grammar's rules. Particularly, we have included
such rules in order to capture: 

\begin{itemize}
\item  Malformed blocks of code (the parser continues after the next semicolon or enclosing
curly brace)
\begin{lstlisting}
declaration
	: ...
	| error ';'
	| error compound_statement
	;

\end{lstlisting}

\item  Malformed statements (the parser continues after the next semicolon)
\begin{lstlisting}
statement
	: ...
	| error ';'
\end{lstlisting}

\item  Malformed expressions (the parser continues after the next semicolon or enclosing
parenthesis)
\begin{lstlisting}
primary_expression
	: ...
	| error
\end{lstlisting}

\item  Malformed argument lists (the parser continues after the next enclosing parenthesis)
\begin{lstlisting}
function_definition
	: ...
	| type IDENTIFIER '(' error ')'
\end{lstlisting}
\end{itemize}


\subsubsection{Semantic errors}

\subsubsection{Remarks about error handling}
These strategies allows us to display a reasonable amount of errors before the program is unable
to proceed and terminates. In fact the parser should be able to finish (albeit not correctly)
the syntax tree even when errors are found in several situations.
The error messages are displayed as they are found, and since the
scanner returns a token that is never used by the parser, lexical errors also generate syntax
errors. To avoid encumbering the output when errors are found, only error messages are
displayed on invalid input.

\subsection{Syntax tree}
To build the syntax tree, we use the data structures defined in \texttt{node.h} and \texttt{node.c}.
By setting Bison's default data type a pointer to our tree node type, we are now able to start
building our syntax tree as the parser proceeds.
\begin{lstlisting}
%union {
	struct node * node;
}
\end{lstlisting}

The scanner transforms some terminal tokens into leaf nodes for the tree. The structures
are allocated and then passed to the parser via the \texttt{yylval} variable:

\begin{lstlisting}[caption={Example of a lexer rule where a leaf node is created.
This procedure is preformed for
all data types, identifiers and constants.},captionpos=b]
"int"	{
			update_position();
			int t = INT;
			yylval.node = node_init(node_list, t, yytext, NULL);
			return t;
		}
\end{lstlisting}

Then, the parser is instructed to connect these nodes forming the syntax tree.
Nodes are connected for most (except when the \texttt{error} token is present)
grammar productions. In some cases, such as when an identifier is found, a symbol is also added
to the symbol table.

\begin{lstlisting}[caption={Example of a parser rule where nodes are connected.
This procedure is preformed for all productions, except error handlers. Here, a symbol
is also added to the symbol table through the function \texttt{add\_symbol\_var}},captionpos=b]
declarator : type IDENTIFIER 
	{
		$$ = node_init(node_list, 'D', "declarator-variable", $1, $2, NULL);
		add_symbol_var($$);
	}
\end{lstlisting}

\subsection{Symbol table and polymorphic functions}
We use a hash table, defined in \texttt{table.h} and \texttt{table.c}, to implement the symbol
table. At this point, the symbol table only stores variable and function names (and their types).
We, however, are already able to distinguish each function by their signature, rather than
only their name, by analyzing the syntax tree.

Whereas variables are included to the table based solely on their names, a function uses a
combination of both its name and the list if its argument's types to form the key for the hash
table. To do that, we append additional characters to the symbol key as we traverse the
function's argument list from the syntax tree. For example, by parsing the following code
(see attached file ``tests/test\_valid5.c''):

\begin{lstlisting}
int min(int x, int y);
int min(int x, int y, int z);
float min(float x, float y);
float min(float x, float y, float z);
\end{lstlisting}

The following entries would be generated in the symbol table:

\begin{table}[h]
 \centering
\begin{tabular}{c c}
\hline
Symbol    &   Return type \\
\hline
min\_ii    &          int \\
min\_iii   &          int \\
min\_ff    &          float \\
min\_fff   &          float  \\
\hline
\end{tabular}
\end{table}

Each entry still knows their original name, but to be accessed in the table, the
new key must be calculated, thus resolving collisions between functions with the
same name but different signatures.

\subsection{Tests}
Eight sample test files are provided in the folder ./tests.

\paragraph{test{\_}valid1.c} is valid, tests for most recognized keywords and punctuation;
\paragraph{test{\_}valid2.c} is valid, tests for numerical values and loops;
\paragraph{test{\_}valid3.c} is valid, tests for character and string literals;
\paragraph{test{\_}valid4.c} is valid, tests for a slightly more complex program containing several language features;
\paragraph{test{\_}valid5.c} is valid, tests mostly for multiple function declarations;

\paragraph{test{\_}error1.c} is invalid, and contain the following errors:
\begin{itemize}
\item Line 1, column 25: syntax error, unexpected '*', expecting IDENTIFIER
\item Line 2, column 22: lexical error, unrecognized token ('?')
\item Line 2, column 22: syntax error, unexpected UNRECOGNIZED\_TOKEN
\item Line 2, column 26: lexical error, unrecognized token (':')
\item Line 2, column 28: lexical error, invalid character constant. (char constant too long)
\end{itemize}

\paragraph{test{\_}error2.c} is invalid, and contain the following errors:
\begin{itemize}
\item Line 1, column 1: lexical error, unrecognized token ('\#')
\item Line 1, column 1: syntax error, unexpected UNRECOGNIZED\_TOKEN, expecting VOID or INT or FLOAT or CHAR
\item Line 1, column 16: lexical error, unrecognized token ('.')
\item Line 4, column 9: lexical error, identifier exceeds 32 characters.
\item Line 4, column 52: lexical error, identifier exceeds 32 characters.
\item Line 6, column 14: lexical error, invalid character constant.
\item Line 6, column 14: syntax error, unexpected INVALID\_CHAR\_CONST
\end{itemize}

\paragraph{test{\_}error3.c} is invalid, and contain the following errors:
\begin{itemize}
\item Line 2, column 12: syntax error, unexpected IDENTIFIER
\item Line 3, column 15: syntax error, unexpected ')', expecting IDENTIFIER
\item Line 4, column 19: syntax error, unexpected ';', expecting '[' or ',' or ')'
\item Line 7, column 1: syntax error, unexpected VOID, expecting ';' or '\{'
\item Line 12, column 12: syntax error, unexpected ')', expecting IDENTIFIER or STRING\_LITERAL or CONSTANT or '('
\item Line 41, column 27: syntax error, unexpected ';'
\end{itemize}

Lines and columns are 1-indexed and the columns should point to where the error begins.
Note, however, that tabs (\textbackslash t) count as if they had a length of four characters.

\subsection{Additional remarks}
Overall, this phase of the project presented itself more challenging than the previous ones,
given the more complex nature of the parser, as opposed to the scanner. In particular, a
remarkably nasty memory leak accompanied by several segfaults showed up as the
syntax tree was being built while parsing input with errors. The solution for that was to
reserve ownership of the allocated tree nodes to a vector that stores every node as they
are allocated (\texttt{Nodelist * node\_list} in \texttt{main.c}).

\printbibliography

\end{document}
